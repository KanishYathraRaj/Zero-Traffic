{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumo_rl\n",
    "\n",
    "# Initialize the SUMO environment\n",
    "env = sumo_rl.environment.env.SumoEnvironment(\n",
    "    net_file='third.net.xml',   # Path to your network file\n",
    "    route_file='third.rou.xml',   # Path to your route file\n",
    "    use_gui=True,                         # If you want to visualize the simulation\n",
    "    num_seconds=20000,                    # Total simulation time\n",
    "    single_agent=False,                    # Single agent or multi-agent setting\n",
    "    reward_fn='diff-waiting-time',        # Reward function (waiting time, throughput, etc.)\n",
    "    min_green=5,                          # Minimum green time\n",
    "    max_green=50,                         # Maximum green time\n",
    ")\n",
    "\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "for step in range(1000):\n",
    "    actions = {\n",
    "    'B1': env.action_spaces('B1').sample(),  # Action for traffic light B1\n",
    "    'C1': env.action_spaces('C1').sample()   # Action for traffic light C1\n",
    "    }\n",
    "\n",
    "    obs, rewards, dones, infos = env.step(actions)\n",
    "    \n",
    "    print(f\"Step: {step}\")\n",
    "    print(f\"Actions: {actions}\")\n",
    "    #print(f\"Observations: {obs}\")\n",
    "    print(f\"Rewards: {rewards}\")\n",
    "    print(f\"Done: {dones}\")\n",
    "\n",
    "    # Check if all traffic signals are done\n",
    "    if all(dones.values()):\n",
    "        break\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumo_rl\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "# Initialize the SUMO environment\n",
    "env = sumo_rl.environment.env.SumoEnvironment(\n",
    "    net_file='third.net.xml',   # Path to your network file\n",
    "    route_file='third.rou.xml',   # Path to your route file\n",
    "    use_gui=True,                         # If you want to visualize the simulation\n",
    "    num_seconds=20000,                    # Total simulation time\n",
    "    single_agent=False,                    # Single agent or multi-agent setting\n",
    "    reward_fn='diff-waiting-time',        # Reward function (waiting time, throughput, etc.)\n",
    "    min_green=5,                          # Minimum green time\n",
    "    max_green=50,                         # Maximum green time\n",
    ")\n",
    "\n",
    "# Check if the environment follows the OpenAI Gym interface (for debugging purposes)\n",
    "# check_env(env)\n",
    "\n",
    "# Wrap the environment for Stable Baselines3\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Define the RL model (PPO in this case)\n",
    "model = PPO('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# Optionally set up a callback to save models during training\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./models/',\n",
    "                                         name_prefix='rl_model')\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=200000, callback=checkpoint_callback)\n",
    "\n",
    "# After training, save the model\n",
    "model.save(\"ppo_sumo_traffic\")\n",
    "\n",
    "# Load the trained model (if you want to test it later)\n",
    "# model = PPO.load(\"ppo_sumo_traffic\")\n",
    "\n",
    "# Testing the trained model\n",
    "# obs , info = env.reset()\n",
    "# for step in range(1000):\n",
    "#     # Use the trained model to predict actions\n",
    "#     actions, _states = model.predict(obs)\n",
    "    \n",
    "#     obs, rewards, dones, infos = env.step(actions)\n",
    "    \n",
    "#     print(f\"Step: {step}\")\n",
    "#     print(f\"Actions: {actions}\")\n",
    "#     print(f\"Rewards: {rewards}\")\n",
    "    \n",
    "#     # Check if all traffic signals are done\n",
    "#     if all(dones):\n",
    "#         break\n",
    "\n",
    "# env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network with Single traffic light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import sumo_rl\n",
    "env = gym.make('sumo-rl-v0',\n",
    "                net_file='third.net.xml',  \n",
    "                route_file='third.rou.xml',\n",
    "                out_csv_name='path_to_output.csv',\n",
    "                use_gui=True,\n",
    "                num_seconds=100000)\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    next_obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    done = terminated or truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kanish Yathra Raj R\\anaconda3\\Lib\\site-packages\\pettingzoo\\utils\\conversions.py:132: UserWarning: The base environment `sumo_rl_v0` does not have a `render_mode` defined.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n",
      "['B1', 'C1']\n"
     ]
    }
   ],
   "source": [
    "import sumo_rl\n",
    "env = sumo_rl.parallel_env(net_file='third.net.xml',\n",
    "                  route_file='third.rou.xml',\n",
    "                  use_gui=True,\n",
    "                  num_seconds=550)\n",
    "observations = env.reset()\n",
    "epo = 1 \n",
    "while env.agents:\n",
    "    actions = {agent: env.action_space(agent).sample() for agent in env.agents}  # this is where you would insert your policy\n",
    "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "    # if( epo % 5 == 0):\n",
    "    #     print(f\" {rewards[\"B1\"]} , {rewards[\"C1\"]} \")\n",
    "    epo += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
